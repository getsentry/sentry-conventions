{
  "key": "gen_ai.usage.input_tokens.cached",
  "brief": "The number of cached tokens used to process the AI input (prompt).",
  "type": "integer",
  "pii": {
    "key": "false"
  },
  "is_in_otel": false,
  "example": 50
}
